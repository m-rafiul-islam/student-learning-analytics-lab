{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSCZnhvlGXz05bAoMGKXju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-rafiul-islam/student-learning-analytics-lab/blob/main/student_risk_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV-PPW8C4m8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104a2a79-b968-403d-acc5-245be7608ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-14 21:17:16--  https://archive.ics.uci.edu/static/public/349/open+university+learning+analytics+dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘data-oulad.zip’\n",
            "\n",
            "data-oulad.zip          [    <=>             ]  44.58M  70.7MB/s    in 0.6s    \n",
            "\n",
            "2026-02-14 21:17:17 (70.7 MB/s) - ‘data-oulad.zip’ saved [46748244]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://archive.ics.uci.edu/static/public/349/open+university+learning+analytics+dataset.zip\" -O data-oulad.zip\n",
        "!unzip  data-oulad.zip -d oulad-data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaM5azyM92ot",
        "outputId": "c723ec98-523e-43a1-c0ad-40bc55d22454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data-oulad.zip\n",
            "  inflating: oulad-data/assessments.csv  \n",
            "  inflating: oulad-data/courses.csv  \n",
            "  inflating: oulad-data/studentAssessment.csv  \n",
            "  inflating: oulad-data/studentInfo.csv  \n",
            "  inflating: oulad-data/studentRegistration.csv  \n",
            "  inflating: oulad-data/studentVle.csv  \n",
            "  inflating: oulad-data/vle.csv      \n",
            "  inflating: oulad-data/OULAD.names  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "rPKLGChpLL_e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2c4YzuoLFOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# OULAD Colab Template: Student Risk Prediction\n",
        "# ===========================================\n",
        "# Goal: Predict at-risk students (Fail/Withdrawn) using early activity + assessments\n",
        "# Data: OULAD CSVs (studentInfo, studentRegistration, assessments, studentAssessment,\n",
        "#       studentVle, vle, courses)\n",
        "# -------------------------------------------\n",
        "\n",
        "# ============== 0) SETUP ==============\n",
        "!pip -q install xgboost shap\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, f1_score, accuracy_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# ============== 1) UPLOAD & UNZIP DATA ==============\n",
        "# Upload `oulad.zip` to Colab (Files panel), then run this cell.\n",
        "\n",
        "DATA_DIR = \"/content/oulad_data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "zip_path = \"/content/oulad.zip\"\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(DATA_DIR)\n",
        "    print(\"✅ Unzipped oulad.zip into:\", DATA_DIR)\n",
        "else:\n",
        "    raise FileNotFoundError(\"❌ /content/oulad.zip not found. Upload oulad.zip to Colab first.\")\n",
        "\n",
        "# Helper: locate CSVs even if nested in a folder\n",
        "def find_csv(filename, base_dir):\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "needed = [\n",
        "    \"studentInfo.csv\",\"studentRegistration.csv\",\"assessments.csv\",\n",
        "    \"studentAssessment.csv\",\"studentVle.csv\",\"vle.csv\",\"courses.csv\"\n",
        "]\n",
        "paths = {f: find_csv(f, DATA_DIR) for f in needed}\n",
        "missing = [k for k,v in paths.items() if v is None]\n",
        "if missing:\n",
        "    raise FileNotFoundError(f\"❌ Missing files: {missing}\\nCheck the zip contents / folder structure.\")\n",
        "print(\"✅ All required CSVs found.\")\n",
        "\n",
        "# ============== 2) LOAD TABLES ==============\n",
        "studentInfo         = pd.read_csv(paths[\"studentInfo.csv\"])\n",
        "studentRegistration = pd.read_csv(paths[\"studentRegistration.csv\"])\n",
        "assessments         = pd.read_csv(paths[\"assessments.csv\"])\n",
        "studentAssessment   = pd.read_csv(paths[\"studentAssessment.csv\"])\n",
        "studentVle          = pd.read_csv(paths[\"studentVle.csv\"])\n",
        "vle                 = pd.read_csv(paths[\"vle.csv\"])\n",
        "courses             = pd.read_csv(paths[\"courses.csv\"])\n",
        "\n",
        "print(\"studentInfo:\", studentInfo.shape)\n",
        "print(\"studentRegistration:\", studentRegistration.shape)\n",
        "print(\"assessments:\", assessments.shape)\n",
        "print(\"studentAssessment:\", studentAssessment.shape)\n",
        "print(\"studentVle:\", studentVle.shape)\n",
        "print(\"vle:\", vle.shape)\n",
        "print(\"courses:\", courses.shape)\n",
        "\n",
        "studentInfo.head()\n",
        "\n",
        "# ============== 3) DEFINE TARGET LABEL ==============\n",
        "# final_result: Pass, Fail, Withdrawn, Distinction\n",
        "# Binary: at risk = Fail or Withdrawn (customize as needed)\n",
        "\n",
        "TARGET_COL = \"final_result\"\n",
        "AT_RISK = {\"Fail\", \"Withdrawn\"}\n",
        "\n",
        "df_target = studentInfo[[\"id_student\",\"code_module\",\"code_presentation\", TARGET_COL]].copy()\n",
        "df_target[\"y_at_risk\"] = df_target[TARGET_COL].isin(AT_RISK).astype(int)\n",
        "\n",
        "print(df_target[\"y_at_risk\"].value_counts())\n",
        "\n",
        "# ============== 4) EARLY-WEEK FEATURE ENGINEERING ==============\n",
        "# Use only activity/assessments up to EARLY_WEEK (weeks from start).\n",
        "EARLY_WEEK = 4\n",
        "CUTOFF_DAYS = EARLY_WEEK * 7\n",
        "\n",
        "# ---- 4A) Registration features ----\n",
        "reg_feats = studentRegistration[[\n",
        "    \"id_student\",\"code_module\",\"code_presentation\",\n",
        "    \"date_registration\",\"date_unregistration\"\n",
        "]].copy()\n",
        "\n",
        "reg_feats[\"registered_early\"] = (reg_feats[\"date_registration\"] <= 0).astype(int)\n",
        "reg_feats[\"unregistered\"] = reg_feats[\"date_unregistration\"].notna().astype(int)\n",
        "reg_feats[\"unregistered_by_cutoff\"] = (\n",
        "    reg_feats[\"date_unregistration\"].notna() & (reg_feats[\"date_unregistration\"] <= CUTOFF_DAYS)\n",
        ").astype(int)\n",
        "\n",
        "# ---- 4B) Assessment aggregates up to cutoff ----\n",
        "assess_merged = studentAssessment.merge(\n",
        "    assessments[[\"id_assessment\",\"code_module\",\"code_presentation\",\"date\",\"weight\",\"assessment_type\"]],\n",
        "    on=\"id_assessment\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "assess_early = assess_merged[assess_merged[\"date\"] <= CUTOFF_DAYS].copy()\n",
        "\n",
        "assess_feats = assess_early.groupby([\"id_student\",\"code_module\",\"code_presentation\"]).agg(\n",
        "    n_assess_submitted=(\"score\",\"count\"),\n",
        "    mean_score=(\"score\",\"mean\"),\n",
        "    max_score=(\"score\",\"max\"),\n",
        "    min_score=(\"score\",\"min\"),\n",
        "    sum_weight=(\"weight\",\"sum\")\n",
        ").reset_index()\n",
        "\n",
        "# ---- 4C) VLE click aggregates up to cutoff ----\n",
        "vle_merged = studentVle.merge(\n",
        "    vle[[\"id_site\",\"activity_type\"]],\n",
        "    on=\"id_site\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "vle_early = vle_merged[vle_merged[\"date\"] <= CUTOFF_DAYS].copy()\n",
        "\n",
        "vle_total = vle_early.groupby([\"id_student\",\"code_module\",\"code_presentation\"]).agg(\n",
        "    total_clicks=(\"sum_click\",\"sum\"),\n",
        "    active_days=(\"date\",\"nunique\")\n",
        ").reset_index()\n",
        "\n",
        "vle_by_type = (vle_early\n",
        "               .groupby([\"id_student\",\"code_module\",\"code_presentation\",\"activity_type\"])[\"sum_click\"]\n",
        "               .sum()\n",
        "               .reset_index())\n",
        "\n",
        "vle_pivot = vle_by_type.pivot_table(\n",
        "    index=[\"id_student\",\"code_module\",\"code_presentation\"],\n",
        "    columns=\"activity_type\",\n",
        "    values=\"sum_click\",\n",
        "    fill_value=0\n",
        ").reset_index()\n",
        "\n",
        "# ============== 5) BUILD MASTER MODEL TABLE ==============\n",
        "demo_cols = [\n",
        "    \"id_student\",\"code_module\",\"code_presentation\",\n",
        "    \"gender\",\"region\",\"highest_education\",\"imd_band\",\n",
        "    \"age_band\",\"num_of_prev_attempts\",\"studied_credits\",\n",
        "    \"disability\"\n",
        "]\n",
        "\n",
        "df = studentInfo[demo_cols].merge(\n",
        "    df_target[[\"id_student\",\"code_module\",\"code_presentation\",\"y_at_risk\"]],\n",
        "    on=[\"id_student\",\"code_module\",\"code_presentation\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "df = df.merge(reg_feats, on=[\"id_student\",\"code_module\",\"code_presentation\"], how=\"left\")\n",
        "df = df.merge(assess_feats, on=[\"id_student\",\"code_module\",\"code_presentation\"], how=\"left\")\n",
        "df = df.merge(vle_total, on=[\"id_student\",\"code_module\",\"code_presentation\"], how=\"left\")\n",
        "df = df.merge(vle_pivot, on=[\"id_student\",\"code_module\",\"code_presentation\"], how=\"left\")\n",
        "\n",
        "# Fill missing numeric engineered features with 0\n",
        "num_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "num_all.remove(\"y_at_risk\")\n",
        "df[num_all] = df[num_all].fillna(0)\n",
        "\n",
        "print(\"Master df:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "# ============== 6) TRAIN/TEST SPLIT ==============\n",
        "X = df.drop(columns=[\"y_at_risk\"])\n",
        "y = df[\"y_at_risk\"]\n",
        "\n",
        "# remove identifier(s)\n",
        "X = X.drop(columns=[\"id_student\"], errors=\"ignore\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(\"Categorical cols:\", cat_cols)\n",
        "print(\"Numeric cols:\", len(num_cols))\n",
        "\n",
        "# ============== 7) PREPROCESSING PIPELINE ==============\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", \"passthrough\", num_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ============== 8) LOGISTIC REGRESSION BASELINE ==============\n",
        "logreg = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"model\", LogisticRegression(max_iter=2000))\n",
        "])\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "p = logreg.predict_proba(X_test)[:, 1]\n",
        "yhat = (p >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n=== Logistic Regression ===\")\n",
        "print(\"AUC:\", roc_auc_score(y_test, p))\n",
        "print(\"F1:\", f1_score(y_test, yhat))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yhat))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
        "print(\"\\nReport:\\n\", classification_report(y_test, yhat, digits=3))\n",
        "\n",
        "# ============== 9) RANDOM FOREST ==============\n",
        "rf = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"model\", RandomForestClassifier(\n",
        "        n_estimators=400, random_state=RANDOM_STATE,\n",
        "        class_weight=\"balanced_subsample\", n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "p = rf.predict_proba(X_test)[:, 1]\n",
        "yhat = (p >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n=== Random Forest ===\")\n",
        "print(\"AUC:\", roc_auc_score(y_test, p))\n",
        "print(\"F1:\", f1_score(y_test, yhat))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yhat))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
        "\n",
        "# ============== 10) OPTIONAL: XGBOOST ==============\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"model\", XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=RANDOM_STATE,\n",
        "        eval_metric=\"logloss\",\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "p = xgb.predict_proba(X_test)[:, 1]\n",
        "yhat = (p >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n=== XGBoost ===\")\n",
        "print(\"AUC:\", roc_auc_score(y_test, p))\n",
        "print(\"F1:\", f1_score(y_test, yhat))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yhat))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
        "\n",
        "# ============== 11) OPTIONAL: SHAP (XGBoost) ==============\n",
        "import shap\n",
        "\n",
        "prep = xgb.named_steps[\"prep\"]\n",
        "model = xgb.named_steps[\"model\"]\n",
        "\n",
        "X_test_t = prep.transform(X_test)\n",
        "\n",
        "ohe = prep.named_transformers_[\"cat\"]\n",
        "cat_feature_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
        "feature_names = cat_feature_names + num_cols\n",
        "\n",
        "sample_n = min(2000, X_test_t.shape[0])\n",
        "idx = np.random.RandomState(RANDOM_STATE).choice(X_test_t.shape[0], sample_n, replace=False)\n",
        "X_shap = X_test_t[idx]\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_shap)\n",
        "\n",
        "shap.summary_plot(shap_values, features=X_shap, feature_names=feature_names, show=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============== 12) SAVE MASTER TABLE USED FOR MODELING ==============\n",
        "out_path = f\"/content/oulad_master_week{EARLY_WEEK}.csv\"\n",
        "df.to_csv(out_path, index=False)\n",
        "print(\"✅ Saved:\", out_path)\n",
        "\n",
        "# Tip: change EARLY_WEEK to 2,4,6,8 and compare AUC/F1 for \"early warning\" analysis.\n"
      ],
      "metadata": {
        "id": "NLHgvanPKQzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}